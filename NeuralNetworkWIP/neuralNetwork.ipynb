{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1ac945",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6425ceb1-427b-4152-94d2-565236d3ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import sys\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from torchvision import datasets, transforms #currently unused\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from scipy.signal import argrelextrema\n",
    "import pandas as pd\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00d9f86-b817-4273-adff-fea1a4567091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"xpu\"\n",
    "    if torch.xpu.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a624c81",
   "metadata": {},
   "source": [
    "## Parameters and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a53c7-731e-4cf8-9cc1-1ce33dce0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "img_width = 200\n",
    "img_height = 50\n",
    "num_characters = 26 #TODO: change for function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb377a4",
   "metadata": {},
   "source": [
    "## create segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62559818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import SplitImage\n",
    "\n",
    "si = SplitImage(\"src/pmml_project/img/a01-043.png\")\n",
    "handwritten_area = si.handwritten_area()\n",
    "handwritten_area.save('handwritten-a01-043.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4e044",
   "metadata": {},
   "source": [
    "### Create the horizontal projection of gray values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831410b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"handwritten-a01-043.png\")\n",
    "pixels = np.array(img)\n",
    "horizontal_projection = np.sum(255 - pixels, axis=1)\n",
    "#plt.plot(horizontal_projection)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a055c",
   "metadata": {},
   "source": [
    "### Find local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://www.kaggle.com/code/irinaabdullaeva/text-segmentation\n",
    "\n",
    "def smooth(x, window_len=70, window='hanning'):\n",
    "#     if x.ndim != 1:\n",
    "#         raise ValueError(\"smooth only accepts 1 dimension arrays.\") \n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\") \n",
    "    if window_len<3:\n",
    "        return x\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "    s = np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w = np.ones(window_len,'d')\n",
    "    else:\n",
    "        w = eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y = np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n",
    "smoothed = smooth(horizontal_projection, 45, window='flat')\n",
    "plt.plot(smoothed)\n",
    "\n",
    "local_minima = argrelextrema(smoothed, np.less)\n",
    "local_minima = np.array(local_minima).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78167f",
   "metadata": {},
   "source": [
    "### Cropping lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_lines(local_minima, threshold=0):\n",
    "    x1 = 0\n",
    "    cropped = []\n",
    "    diff = []\n",
    "    for i, min in enumerate(local_minima):\n",
    "        x2 = min\n",
    "        #print(f\"x1 = {x1}, x2 = {x2}, diff = {x2-x1}\")\n",
    "        if x2-x1 >= threshold:\n",
    "            cropped.append((x1, x2))\n",
    "        x1 = min\n",
    "    return cropped\n",
    "\n",
    "def show_cropped_lines(img, cropped):\n",
    "    plots = len(cropped)\n",
    "    for i, l in enumerate(cropped):\n",
    "        line = img[l[0]:l[1]]\n",
    "        plt.subplot(plots, 1, i+1)\n",
    "        plt.axis('off')\n",
    "        _ = plt.imshow(line, cmap='gray')\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "\n",
    "cropped = crop_lines(local_minima, 100)\n",
    "cropped = [(int(x1), int(x2)) for x1, x2 in cropped]\n",
    "print(cropped)\n",
    "show_cropped_lines(pixels, cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741aab7e",
   "metadata": {},
   "source": [
    "### Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed1a9a0-7e38-41f9-a0d3-1c877d6ec030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_number</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>segment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a06-119</td>\n",
       "      <td>a06-119.png</td>\n",
       "      <td>/084/a06-119.png</td>\n",
       "      <td>718</td>\n",
       "      <td>893</td>\n",
       "      <td>Note circulation soared for the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a06-119</td>\n",
       "      <td>a06-119.png</td>\n",
       "      <td>/084/a06-119.png</td>\n",
       "      <td>901</td>\n",
       "      <td>1070</td>\n",
       "      <td>sixth successive week - this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a06-119</td>\n",
       "      <td>a06-119.png</td>\n",
       "      <td>/084/a06-119.png</td>\n",
       "      <td>1077</td>\n",
       "      <td>1250</td>\n",
       "      <td>time by more than 15,000,000 last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a06-119</td>\n",
       "      <td>a06-119.png</td>\n",
       "      <td>/084/a06-119.png</td>\n",
       "      <td>1259</td>\n",
       "      <td>1432</td>\n",
       "      <td>week. And that brought the figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a06-119</td>\n",
       "      <td>a06-119.png</td>\n",
       "      <td>/084/a06-119.png</td>\n",
       "      <td>1438</td>\n",
       "      <td>1614</td>\n",
       "      <td>to a record 2,415,000,000. This was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>a01-014</td>\n",
       "      <td>a01-014x.png</td>\n",
       "      <td>/008/a01-014x.png</td>\n",
       "      <td>1745</td>\n",
       "      <td>1926</td>\n",
       "      <td>and the talks fall through. There are bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>a01-014</td>\n",
       "      <td>a01-014x.png</td>\n",
       "      <td>/008/a01-014x.png</td>\n",
       "      <td>1926</td>\n",
       "      <td>2108</td>\n",
       "      <td>to be demonstrations.” Yesterday Sir Roy’s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>a01-014</td>\n",
       "      <td>a01-014x.png</td>\n",
       "      <td>/008/a01-014x.png</td>\n",
       "      <td>2108</td>\n",
       "      <td>2289</td>\n",
       "      <td>chief aide, Mr. Julius Greenfield, telephoned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>a01-014</td>\n",
       "      <td>a01-014x.png</td>\n",
       "      <td>/008/a01-014x.png</td>\n",
       "      <td>2289</td>\n",
       "      <td>2463</td>\n",
       "      <td>his chief a report on his talks with Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>a01-014</td>\n",
       "      <td>a01-014x.png</td>\n",
       "      <td>/008/a01-014x.png</td>\n",
       "      <td>2463</td>\n",
       "      <td>2637</td>\n",
       "      <td>Macmillan at Chequers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4357 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_number     file_name          file_path  segment_start  segment_end  \\\n",
       "0        a06-119   a06-119.png   /084/a06-119.png            718          893   \n",
       "1        a06-119   a06-119.png   /084/a06-119.png            901         1070   \n",
       "2        a06-119   a06-119.png   /084/a06-119.png           1077         1250   \n",
       "3        a06-119   a06-119.png   /084/a06-119.png           1259         1432   \n",
       "4        a06-119   a06-119.png   /084/a06-119.png           1438         1614   \n",
       "...          ...           ...                ...            ...          ...   \n",
       "4352     a01-014  a01-014x.png  /008/a01-014x.png           1745         1926   \n",
       "4353     a01-014  a01-014x.png  /008/a01-014x.png           1926         2108   \n",
       "4354     a01-014  a01-014x.png  /008/a01-014x.png           2108         2289   \n",
       "4355     a01-014  a01-014x.png  /008/a01-014x.png           2289         2463   \n",
       "4356     a01-014  a01-014x.png  /008/a01-014x.png           2463         2637   \n",
       "\n",
       "                                       segment_text  \n",
       "0                   Note circulation soared for the  \n",
       "1                      sixth successive week - this  \n",
       "2                 time by more than 15,000,000 last  \n",
       "3                 week. And that brought the figure  \n",
       "4               to a record 2,415,000,000. This was  \n",
       "...                                             ...  \n",
       "4352    and the talks fall through. There are bound  \n",
       "4353     to be demonstrations.” Yesterday Sir Roy’s  \n",
       "4354  chief aide, Mr. Julius Greenfield, telephoned  \n",
       "4355       his chief a report on his talks with Mr.  \n",
       "4356                         Macmillan at Chequers.  \n",
       "\n",
       "[4357 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"segments.csv\", delimiter=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84521d4c-7de7-469f-8fe4-ed164240ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define nn datastructure\n",
    "class OCR_dataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, root_path: str):\n",
    "        self.df = df\n",
    "        self.root_path = root_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.root_path + self.df.iloc[idx]['file_path']\n",
    "        start = self.df.iloc[idx]['segment_start']\n",
    "        end = self.df.iloc[idx]['segment_end']\n",
    "        text = self.df.iloc[idx]['segment_text']\n",
    "\n",
    "        image = Image.open(path)\n",
    "        width, _ = image.size\n",
    "        image = image.crop((0, start, width, end))\n",
    "        image = pil_to_tensor(image)\n",
    "        return image, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a5142-978e-4bb8-aa47-135a8e4319a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/jan/.cache/kagglehub/datasets/naderabdelghany/iam-handwritten-forms-dataset/versions/1/data\"\n",
    "data = OCR_dataset(df, root_path)\n",
    "generator = torch.Generator().manual_seed(299792458) # Generator for reproducability\n",
    "train_data, eval_data, test_data = random_split(data, [.8, .1, .1], generator)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=eval_data,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa9fcc",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f245a-442d-4807-b1dd-e8bc9d04d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define nn layers\n",
    "class OCR_neural_network(nn.Module):\n",
    "    def __init__(self, img_width, img_height, num_characters):\n",
    "        super().__init__()\n",
    "        self.rnn_height = img_height//4\n",
    "        self.rnn_width = img_width//4\n",
    "        self.rnn_feature_number = self.rnn_height * 64\n",
    "        \n",
    "        self.conv_pooling_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding = 1),\n",
    "            nn.ReLu(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding = 1),\n",
    "            nn.ReLu(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.after_resize_stack = nn.Sequential(\n",
    "            nn.Linear(self.rnn_feature_number, 64),\n",
    "            nn.ReLu(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "            \n",
    "        self.rnn1 = nn.LSTM(64, 128, batch_first = True, bidirectional = True, dropout = 0.25)\n",
    "        self.rnn2 = nn.LSTM(256, 64, batch_first = True, bidirectional = True, dropout = 0.25)\n",
    "\n",
    "        self.output_layer = nn.Linear(128, num_characters)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            batch_size, seq_len, channels, height = x.size()\n",
    "            \n",
    "            x = self.conv_pooling_stack(x)\n",
    "    \n",
    "            #reshape for rnn\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = torch.reshape(x, (batch_size, seq_len, channels * height))    \n",
    "            \n",
    "            x = self.after_resize_stack(x)\n",
    "    \n",
    "            x, y = self.rnn1(x) #y is not used\n",
    "            x, y = self.rnn2(x)\n",
    "    \n",
    "            x = self.output_layer(x)\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e24dda-1e9f-4bd6-9d40-dae87b9ced29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of model\n",
    "model = OCR_neural_network(img_width, img_height, num_characters)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88741df-db10-4a1a-a7ee-421be232ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train NN\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for image_data, label in training_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image_data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f32ec",
   "metadata": {},
   "source": [
    "## LLM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94daf882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e746a6fd9dc4a4d848f5235b0585c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm_model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55d7eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " Note circalation soared for the sixth successive week - thir time by more than 15,000,000 last weeb. And that brought the fiyure to a record 2,415,000,000.This was 100,000,000 more than the corresponding week last year and 37,000,000 up onthe 1960 record set last Christmus.Now look at the other side of allthese coins.\n",
      "output:\n",
      " Note circulation soared for the sixth successive week - third time by more than 15,000,000 last week. And that brought the figure to a record 2,415,000,000. This was 100,000,000 more than the corresponding week last year and 37,000,000 up on the 1960 record set last Christmas. Now look at the other side of all these coins.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Note circalation soared for the sixth successive week - \"\\\n",
    "\"thir time by more than 15,000,000 last weeb. \"\\\n",
    "\"And that brought the fiyure to a record 2,415,000,000.\" \\\n",
    "\"This was 100,000,000 more than the corresponding week last year and 37,000,000 up on\"\\\n",
    "\"the 1960 record set last Christmus.\"\\\n",
    "\"Now look at the other side of all\"\\\n",
    "\"these coins.\"\n",
    "\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"You are a text corrector. Only correct spelling and punctuation. Do not edit content. Do not rephrase. Only output the corrected text.\" \\\n",
    "            f\"Input text: {input_text}\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "\n",
    "\n",
    "output = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"input:\\n\", input_text)\n",
    "print(\"output:\\n\", output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455850c9",
   "metadata": {},
   "source": [
    "## calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fffbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [a01-000, a01-003, a01-007, a01-011, a01-014, a01-020, a01-026, a01-030, a01-038, a01-043, a01-049, a01-053, a01-058, a01-063, a01-068, a01-072, a01-077, a01-082, a01-087, a01-091, a01-096, a01-102, a01-107, a01-113, a01-117, a01-122, a01-128, a01-132, a02-000, a02-004, a02-008, a02-012, a02-017, a02-020, a02-024, a02-027, a02-032, a02-037, a02-042, a02-046, a02-050, a02-053, a02-057, a02-062, a02-067, a02-072, a02-078, a02-082, a02-086, a02-090, a02-093, a02-098, a02-102, a02-106, a02-111, a02-116, a02-120, a02-124, a03-006, a03-009, a03-011, a03-014, a03-017, a03-020, a03-023, a03-027, a03-030, a03-034, a03-037, a03-040, a03-043, a03-047, a03-050, a03-054, a03-059, a03-063, a03-066, a03-071, a03-073, a03-080, a03-089, a04-000, a04-003, a04-006, a04-010, a04-015, a04-019, a04-023, a04-027, a04-031, a04-035, a04-039, a04-043, a04-047, a04-050, a04-054, a04-059, a04-066, a04-069, a04-072, ...]\n",
      "\n",
      "[413 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(labels: list, ocr_output: list, llm_output: list) -> float:\n",
    "    if len(labels) != len(ocr_output) or len(ocr_output) != len(llm_output) or len(labels) != len(llm_output):\n",
    "        print(\"correct length\")\n",
    "    \n",
    "    accuracy = 0\n",
    "    return accuracy\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
