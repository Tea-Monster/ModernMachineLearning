{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6425ceb1-427b-4152-94d2-565236d3ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms #currently unused\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00d9f86-b817-4273-adff-fea1a4567091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196a53c7-731e-4cf8-9cc1-1ce33dce0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "img_width = 200\n",
    "img_height = 50\n",
    "num_characters = 26 #TODO: change for function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84521d4c-7de7-469f-8fe4-ed164240ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define nn datastructure\n",
    "class OCR_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return image_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a5142-978e-4bb8-aa47-135a8e4319a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test training split\n",
    "train_data = OCR_dataset(\n",
    "test_data = OCR_dataset(\n",
    "eval_data = OCR_dataset(\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader( #TODO\n",
    "test_dataloader = DataLoader(\n",
    "eval_dataloader = DataLoader("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761f245a-442d-4807-b1dd-e8bc9d04d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define nn layers\n",
    "class OCR_neural_network(nn.Module):\n",
    "    def __init__(self, img_width, img_height, num_characters):\n",
    "        super().__init__()\n",
    "        self.rnn_height = img_height//4\n",
    "        self.rnn_width = img_width//4\n",
    "        self.rnn_feature_number = self.rnn_height * 64\n",
    "        \n",
    "        self.conv_pooling_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding = 1),\n",
    "            nn.ReLu(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding = 1),\n",
    "            nn.ReLu(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.after_resize_stack = nn.Sequential(\n",
    "            nn.Linear(self.rnn_feature_number, 64),\n",
    "            nn.ReLu(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "            \n",
    "        self.rnn1 = nn.LSTM(64, 128, batch_first = True, bidirectional = True, dropout = 0.25)\n",
    "        self.rnn2 = nn.LSTM(256, 64, batch_first = True, bidirectional = True, dropout = 0.25)\n",
    "\n",
    "        self.output_layer = nn.Linear(128, num_characters)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            batch_size, seq_len, channels, height = x.size()\n",
    "            \n",
    "            x = self.conv_pooling_stack(x)\n",
    "    \n",
    "            #reshape for rnn\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = torch.reshape(x, (batch_size, seq_len, channels * height))    \n",
    "            \n",
    "            x = self.after_resize_stack(x)\n",
    "    \n",
    "            x, y = self.rnn1(x) #y is not used\n",
    "            x, y = self.rnn2(x)\n",
    "    \n",
    "            x = self.output_layer(x)\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e24dda-1e9f-4bd6-9d40-dae87b9ced29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of model\n",
    "model = OCR_neural_network(img_width, img_height, num_characters)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88741df-db10-4a1a-a7ee-421be232ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train NN\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for image_data, label in training_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image_data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
